{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Prompt Notebook - Prompt Lab Notebook v1.0.0\nThis notebook contains steps and code to demonstrate inferencing of prompts\ngenerated in Prompt Lab in watsonx.ai. It introduces Python API commands\nfor authentication using API key and prompt inferencing using WML API.\n\n**Note:** Notebook code generated using Prompt Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: [Saving your work in Prompt Lab as a notebook](/docs).\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Creating an access token from the IBM Cloud personal API key\n* Defining a Python class for calling the WML Foundation Model inferencing API\n* Using the class to generate output from a provided text input\n\n# Setup\n\n## Inferencing class\nThis cell defines a class that makes a REST API call to the watsonx Foundation Model\ninferencing API that we will use to generate output from the provided input.\nThe class takes the access token created in the previous step, and uses it to\nmake a REST API call with input, model id and model parameters. The response\nfrom the API call is returned as the cell output."}, {"metadata": {}, "cell_type": "code", "source": "import requests\n\nclass Prompt:\n    def __init__(self, access_token, project_id):\n        self.access_token = access_token\n        self.project_id = project_id\n\n    def generate(self, input, model_id, parameters):\n        wml_url = \"https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2023-05-28\"\n        Headers = {\n            \"Authorization\": \"Bearer \" + self.access_token,\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\"\n        }\n        data = {\n            \"model_id\": model_id,\n            \"input\": input,\n            \"parameters\": parameters,\n            \"project_id\": self.project_id\n        }\n        response = requests.post(wml_url, json=data, headers=Headers)\n        if response.status_code == 200:\n            return response.json()[\"results\"][0][\"generated_text\"]\n        else:\n            return response.text", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n[documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)."}, {"metadata": {}, "cell_type": "code", "source": "from ibm_cloud_sdk_core import IAMTokenManager\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator, BearerTokenAuthenticator\nimport os, getpass\n\naccess_token = IAMTokenManager(\n    apikey = getpass.getpass(\"Please enter your api key (hit enter): \"),\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n).get_token()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Inferencing\nThis cell demonstrated how we can use the defined class as well as the\ncreated access token to pair it with model id, parameters and input string\nto obtain the response from the the selected foundation model.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"google/flan-ul2\"\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"decoding_method\": \"greedy\",\n    \"max_new_tokens\": 500,\n    \"min_new_tokens\": 50,\n    \"repetition_penalty\": 1\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the project id\nThe API requires project id that provides the context for the call. We will obtain\nthe id from the project in which this notebook runs:"}, {"metadata": {}, "cell_type": "code", "source": "import os\n\nproject_id = os.environ[\"PROJECT_ID\"]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the inferencing input\nFoundation model inferencing API accepts a natural language input that it will use\nto provide the natural language response. The API is sensitive to formatting. Input\nstructure, presence of training steps (one-shot, two-shot learning etc.), as well\nas phrasing all influence the final response and belongs to the emerging discipline of\nPrompt Engineering.\n\nLet us provide the input we got from the Prompt Lab:"}, {"metadata": {}, "cell_type": "code", "source": "prompt_input = \"\"\"Input:\n\nOutput:\nIBM uses  \u201cCore/Flex\u201d approach to handle scalability and enable flexible deployment of the required skills and experience at the right time and right place.\nThe \u201cCore\u201d team will be dedicated to performing high-end activities across different work streams and will be retained within the account for the long term. This approach will provide stability and continuity.\nThe \u201cFlex\u201d team will provide additional staffing capacity to support variable and supplemental project demands and will increase or decrease in size to address dynamic workload, providing necessary scalability and flexibility at an optimal cost. This will help ensure there will be a highly skilled resource pool available which can be used in case of an unpredicted volume surge or to offer a quick resolution in a crisis. Flex team practitioners who gain significant experience in the Client\u2019s environment will be included in the core team when required.\nThe following schematic provides a simple overview of the Core/Flex model:\nDepending on Client\u2019s current and future needs, resources will be assigned to work either as part of the \u201cIBM Core Team\u201d to address Client\u2019s core and critical project services, and/or to the \u201cIBM Flex Team\u201d. The Flex team will be primarily assigned for Sustainment Services, where the workload can be elastic and dynamic.\nAs Client\u2019s project portfolio changes, the demand for skills and system expertise also changes. Resources move between the \u201cFlex\u201d and \u201cCore\u201d Service teams to optimize our delivery capability and maximize the flexibility of service to Client. Additionally, a flexible \u201cIBM Resource Pool\u201d will be used to supplement both the Core and the Flex teams to help deliver the right balance of experience and skills in line with your forecast and then committed demand.\nThe Core/Flex staffing model will be complemented with robust 30-60-90 based Resource Forecasting wherein IBM and Client will jointly manage the forecasting process. Planning horizon needs will be agreed to at the beginning of the project, with sufficient lead time and thresholds for forecasting accuracy. IBM will include in the rolling forecast a description of the role, required technical skills, location, and duration (estimated start and end dates) for each resource. \nMoreover, IBM has built the Technology Assembly Centre (TAC) to optimize overall resource utilization. TAC uses a factory-based model to deliver maximum value through standardized, consistent, and repeatable results. We will also continue to look for opportunities to reduce cost by leveraging large collections of assets and accelerators, as well as industry-leading processes and methods and a large pool of technical and functional resources such as industry SMEs. In the event of an important project milestone or crisis, these SMEs bring unmatched expertise to quickly provide an innovative solution.\n \nHow do you handle data security and privacy with remote working employees ?\n \nIBM allows hybrid work environment, a typical week is made up of time spent working from home plus from IBM offices for 3 days.\nAlso, during mid-March 2020, IBM has had most of our global workforce working remotely across 175 countries and supported all our clients without any interruptions. This is testament of IBM\u2019s agility and capability to adapt to new working environments and challenges.\nIBM was able to overcome the challenges of remote work with following multi-dimensional enablers we have put in place.\nData privacy and confidentiality:\nWhen working from home, we advised our employees to maintain the privacy and confidentiality of the information that is on the screen, on work papers or meetings by taking simple actions like keeping the screen locked when stepping away, shredding any confidential printed material properly and using a headset for meetings.\n\nInput:\n\nOutput:\nIBM uses  \u201cCore/Flex\u201d approach to handle scalability and enable flexible deployment of the required skills and experience at the right time and right place.\nThe \u201cCore\u201d team will be dedicated to performing high-end activities across different work streams and will be retained within the account for the long term. This approach will provide stability and continuity.\nThe \u201cFlex\u201d team will provide additional staffing capacity to support variable and supplemental project demands and will increase or decrease in size to address dynamic workload, providing necessary scalability and flexibility at an optimal cost. This will help ensure there will be a highly skilled resource pool available which can be used in case of an unpredicted volume surge or to offer a quick resolution in a crisis. Flex team practitioners who gain significant experience in the Client\u2019s environment will be included in the core team when required.\nThe following schematic provides a simple overview of the Core/Flex model:\nDepending on Client\u2019s current and future needs, resources will be assigned to work either as part of the \u201cIBM Core Team\u201d to address Client\u2019s core and critical project services, and/or to the \u201cIBM Flex Team\u201d. The Flex team will be primarily assigned for Sustainment Services, where the workload can be elastic and dynamic.\nAs Client\u2019s project portfolio changes, the demand for skills and system expertise also changes. Resources move between the \u201cFlex\u201d and \u201cCore\u201d Service teams to optimize our delivery capability and maximize the flexibility of service to Client. Additionally, a flexible \u201cIBM Resource Pool\u201d will be used to supplement both the Core and the Flex teams to help deliver the right balance of experience and skills in line with your forecast and then committed demand.\nThe Core/Flex staffing model will be complemented with robust 30-60-90 based Resource Forecasting wherein IBM and Client will jointly manage the forecasting process. Planning horizon needs will be agreed to at the beginning of the project, with sufficient lead time and thresholds for forecasting accuracy. IBM will include in the rolling forecast a description of the role, required technical skills, location, and duration (estimated start and end dates) for each resource. \nMoreover, IBM has built the Technology Assembly Centre (TAC) to optimize overall resource utilization. TAC uses a factory-based model to deliver maximum value through standardized, consistent, and repeatable results. We will also continue to look for opportunities to reduce cost by leveraging large collections of assets and accelerators, as well as industry-leading processes and methods and a large pool of technical and functional resources such as industry SMEs. In the event of an important project milestone or crisis, these SMEs bring unmatched expertise to quickly provide an innovative solution.\n \nHow do you handle data security and privacy with remote working employees ?\n \nIBM allows hybrid work environment, a typical week is made up of time spent working from home plus from IBM offices for 3 days.\nAlso, during mid-March 2020, IBM has had most of our global workforce working remotely across 175 countries and supported all our clients without any interruptions. This is testament of IBM\u2019s agility and capability to adapt to new working environments and challenges.\nIBM was able to overcome the challenges of remote work with following multi-dimensional enablers we have put in place.\nData privacy and confidentiality:\nWhen working from home, we advised our employees to maintain the privacy and confidentiality of the information that is on the screen, on work papers or meetings by taking simple actions like keeping the screen locked when stepping away, shredding any confidential printed material properly and using a headset for meetings.\n\nInput:\nHow is IBM\u2019s flexibility and approach to address variations in demand and scaling up when needed ?\n\nOutput:\n\nInput:\nHow is IBM\u2019s flexibility and approach to address variations in demand and scaling up when needed ?\n\nOutput:\n\nInput:\nHow is IBM\u2019s flexibility and approach to address variations in demand and scaling up when needed ?\n\nOutput:\n\"\"\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Execution\nLet us now use the defined variables to create an instance of the class\nwe defined previously and get the response from the selected foundation model:"}, {"metadata": {}, "cell_type": "code", "source": "prompt = Prompt(access_token, project_id)\n\nprompt.generate(prompt_input, model_id, parameters)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing API to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2023 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0}